{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from IPython.core.debugger import set_trace\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path:  C:/Users/Cerberus/Documents/ML/Project/dataset299\n",
      "Image size:  299\n",
      "GPU enabled:  True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 299\n",
    "GPU = True\n",
    "DATA_PATH = \"C:/Users/Cerberus/Documents/ML/Project/dataset299\"\n",
    "\n",
    "print(\"Data path: \",DATA_PATH)\n",
    "print(\"Image size: \",IMG_SIZE)\n",
    "print(\"GPU enabled: \",GPU)\n",
    "\n",
    "if GPU == True:\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "\n",
    "#emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Emotion list for dataset48\n",
    "emotions = [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "#emotions = [\"fear\", \"happy\"]\n",
    "\n",
    "def get_files(emotion): #Define function to get file list, randomly shuffle it and split 80/20\n",
    "    files = glob.glob(\"%s//%s//*\" %(DATA_PATH,emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.6)] #get first 80% of file list\n",
    "    prediction = files[-int(len(files)*0.4):] #get last 20% of file list\n",
    "    return training, prediction\n",
    "\n",
    "def make_sets():\n",
    "    td = []\n",
    "    tl = []\n",
    "    pd = []\n",
    "    pl = []\n",
    "    for emotion in emotions:\n",
    "        training, prediction = get_files(emotion)\n",
    "        #Append data to training and prediction list, and generate labels 0-7\n",
    "        for item in training:\n",
    "            #image = cv2.imread(item) #open image\n",
    "            #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "            td.append(item) #append image array to training data list\n",
    "            tl.append(emotions.index(emotion))\n",
    "\n",
    "        for item in prediction: #repeat above process for prediction set\n",
    "            #image = cv2.imread(item)\n",
    "            #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            pd.append(item)\n",
    "            pl.append(emotions.index(emotion))\n",
    "        \n",
    "       \n",
    "    data_t= {}\n",
    "    for i in range(len(td)):\n",
    "        data_t[td[i]] = tl[i]\n",
    "    \n",
    "    data_p= {}\n",
    "    for i in range(len(pd)):\n",
    "        data_p[pd[i]] = pl[i]\n",
    "\n",
    "    #randomize\n",
    "    keys_t =  list(data_t.keys())      # Python 3; use keys = d.keys() in Python 2\n",
    "    random.shuffle(keys_t)\n",
    "    keys_p =  list(data_p.keys())      # Python 3; use keys = d.keys() in Python 2\n",
    "    random.shuffle(keys_p)\n",
    "\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "        #LOAD data\n",
    "    for k in keys_t:\n",
    "        image = cv2.imread(k)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        training_data.append(gray)\n",
    "        training_labels.append(data_t[k])\n",
    "    \n",
    "    prediction_data = []\n",
    "    prediction_labels = []\n",
    "            #LOAD data\n",
    "    for k in keys_p:\n",
    "        image = cv2.imread(k)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        prediction_data.append(gray)\n",
    "        prediction_labels.append(data_p[k])\n",
    "    return training_data, training_labels, prediction_data, prediction_labels\n",
    "\n",
    "\n",
    "class data_loader(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_input,label_output):\n",
    "        Images, Y = [], []\n",
    "        \n",
    "        for i in range(len(images_input)):\n",
    "            Images.append(images_input[i])\n",
    "            Y.append(label_output[i])\n",
    "\n",
    "        data = [(x, y) for x, y in zip(Images, Y)]\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][0]      \n",
    "        img = img.reshape(1, IMG_SIZE, IMG_SIZE) / 255\n",
    "        \n",
    "        #Input for Conv2D should be Channels x Height x Width\n",
    "        img_tensor = transforms.ToTensor()(img).view(1, IMG_SIZE, IMG_SIZE).float()\n",
    "        label = self.data[index][1]\n",
    "        return (img_tensor, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_set():\n",
    "    td = []\n",
    "    tl = []\n",
    "    for emotion in emotions:\n",
    "        training, prediction = get_files(emotion)\n",
    "        #Append data to training and prediction list, and generate labels 0-7\n",
    "        for item in training:\n",
    "            #image = cv2.imread(item) #open image\n",
    "            #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "            td.append(item) #append image array to training data list\n",
    "            tl.append(emotions.index(emotion))\n",
    "\n",
    "        for item in prediction: #repeat above process for prediction set\n",
    "            #image = cv2.imread(item)\n",
    "            #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            td.append(item)\n",
    "            tl.append(emotions.index(emotion))\n",
    "       \n",
    "    data_t= {}\n",
    "    for i in range(len(td)):\n",
    "        data_t[td[i]] = tl[i]\n",
    "\n",
    "        \n",
    "    #randomize\n",
    "    keys_t =  list(data_t.keys())      # Python 3; use keys = d.keys() in Python 2\n",
    "    random.shuffle(keys_t)\n",
    "\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    #LOAD data\n",
    "    for k in keys_t:\n",
    "        image = cv2.imread(k)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        training_data.append(gray)\n",
    "        training_labels.append(data_t[k])\n",
    "    \n",
    "\n",
    "    return training_data, training_labels\n",
    "\n",
    "\n",
    "\n",
    "def get_chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Return n-sized chunks from l.\"\"\"\n",
    "    chunks = list(get_chunks(l, n))\n",
    "\n",
    "    #print(chunks)    \n",
    "    if(len(chunks[-1]) < n):\n",
    "        chunks[-2] = chunks[-2] + chunks[-1]\n",
    "        del chunks[-1]\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def get_separated_sets(sets,index):\n",
    "    big_one = []\n",
    "    small_one = []\n",
    "    for i in range(len(sets)):\n",
    "        if(i == index):\n",
    "            small_one = sets[i]\n",
    "        else:\n",
    "            big_one = big_one + sets[i]\n",
    "            \n",
    "    return big_one,small_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,dataset):\n",
    "    correct=0\n",
    "    for _, data in enumerate(dataset, 0):\n",
    "        test_x, test_y = data\n",
    "        if GPU == True:\n",
    "            test_x, test_y = test_x.cuda(), test_y.cuda()\n",
    "        \n",
    "        pred=model.forward(test_x)\n",
    "        y_hat=np.argmax(pred.data)\n",
    "        if y_hat.item()==test_y.item():\n",
    "            correct+=1\n",
    "    return correct/len(dataset)\n",
    "\n",
    "\n",
    "def get_stats(model,dataset):\n",
    "    actu_all = []\n",
    "    pred_all = []\n",
    "\n",
    "    for _, data in enumerate(dataset, 0):\n",
    "        test_x, test_y = data\n",
    "        if GPU == True:\n",
    "            test_x, test_y = test_x.cuda(), test_y.cuda()\n",
    "            \n",
    "        pred=model.forward(test_x)\n",
    "        y_hat=np.argmax(pred.data)\n",
    "        \n",
    "        if GPU == True:\n",
    "            test_y = test_y.cpu()\n",
    "            y_hat = y_hat.cpu()\n",
    "        \n",
    "        np_actu_y = test_y.data.numpy()[0]\n",
    "        np_pred_y = y_hat.data.numpy().item()\n",
    "\n",
    "        actu_all.append(np_actu_y)\n",
    "        pred_all.append(np_pred_y)\n",
    "\n",
    "    df_confusion = confusion_matrix(actu_all,pred_all)\n",
    "    stats = classification_report(actu_all, pred_all)\n",
    "    return df_confusion,stats\n",
    "\n",
    "def get_label_quantity(label_set):\n",
    "    myset = set(label_set)\n",
    "    labels = np.zeros(len(myset))\n",
    "    for i in range(len(label_set)):\n",
    "        labels[label_set[i]] += 1 \n",
    "    return labels\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t/p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}i\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n",
      "[2, 1, 6, 3, 3, 2, 2, 0, 6, 4, 0, 6, 0, 4, 2, 2, 4, 6, 2, 5, 4, 2, 4, 1, 1, 0, 1, 5, 0, 6, 4, 2, 6, 2, 6, 4, 3, 4, 6, 3, 6, 6, 6, 0, 2, 6, 4, 2, 4, 4, 4, 6, 6, 4, 5, 6, 6, 3, 4, 3, 6, 6, 2, 0, 6, 6, 0, 0, 2, 0, 4, 6, 0, 2, 2, 0, 4, 4, 2, 5, 6, 1, 0, 4, 0, 4, 4, 2, 5, 4, 5, 6, 4, 6, 2, 6, 0, 5, 4, 2, 3, 4, 6, 1, 2, 5, 0, 5, 6, 6, 6, 6, 3, 6, 3, 5, 5, 2, 6, 4, 4, 4, 2, 3, 1, 0, 2, 0]\n",
      "training : [27. 10. 35. 15. 41. 16. 48.]\n",
      "prediction : [18.  7. 23. 10. 27. 11. 32.]\n",
      "Sum Training:  192.0\n",
      "Sum Testing:  128.0\n"
     ]
    }
   ],
   "source": [
    "training_data, training_labels, prediction_data, prediction_labels = make_sets()\n",
    "\n",
    "train_dataset = data_loader(training_data,training_labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = data_loader(prediction_data,prediction_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(training_data[0].shape)\n",
    "print(prediction_labels)\n",
    "print(\"training :\",get_label_quantity(training_labels))\n",
    "print(\"prediction :\",get_label_quantity(prediction_labels))\n",
    "print(\"Sum Training: \", np.sum(get_label_quantity(training_labels)))\n",
    "print(\"Sum Testing: \", np.sum(get_label_quantity(prediction_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL\n",
    "#\n",
    "OUTPUT_CONV = 27\n",
    "\n",
    "#img -> 48*48\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 15)\n",
    "        self.avgpool2d = nn.AvgPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(10,10,12)\n",
    "        self.maxpool2d = nn.MaxPool2d(5,5,2)\n",
    "        self.fc1 = nn.Linear(10*OUTPUT_CONV*OUTPUT_CONV, 20)\n",
    "        self.fc2 = nn.Linear(20, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x \", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(\"conv1 \", x.shape)\n",
    "        x = self.avgpool2d(x)\n",
    "        #print(\"avgpool2d \", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(\"conv2 \", x.shape)\n",
    "        x = self.maxpool2d(x)\n",
    "        #print(\"maxpool2d \", x.shape)\n",
    "        x = x.view(-1, 10*OUTPUT_CONV*OUTPUT_CONV)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        result = F.relu(self.fc2(x))\n",
    "        #result = F.softmax(x, dim=1)\n",
    "        return result\n",
    "\n",
    "def trainClassifier(net,train_set,test_set,criterion,optimizer,epochs,volubile=False,security=False):\n",
    "    history = []\n",
    "    sec_limit = 6\n",
    "    counter_sec = 0\n",
    "    for epoch in range(1, epochs+1):\n",
    "        if volubile == True:  \n",
    "            print('Epoch {}/{}'.format(epoch, epochs))\n",
    "            print('-' * 10)\n",
    "        \n",
    "        for step, data in enumerate(train_set, 0):\n",
    "            train_x, train_y = data\n",
    "            if GPU == True:\n",
    "                train_x, train_y = train_x.cuda(), train_y.cuda()\n",
    "            else:\n",
    "                train_y = torch.LongTensor(np.array(train_y))\n",
    "                \n",
    "            y_hat = net.forward(train_x)\n",
    "            \n",
    "            loss = criterion(y_hat, train_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if security == True:\n",
    "            if len(history) > 0:\n",
    "                if loss.item() == history[-1]:\n",
    "                    counter_sec += 1\n",
    "                \n",
    "        if counter_sec >= sec_limit:\n",
    "            print('*'*35)\n",
    "            print(\"NO TRAINING: \",sec_limit,\" times the same loss\")\n",
    "            print('*'*35)\n",
    "            break\n",
    "            \n",
    "        history.append(loss.item())\n",
    "        if volubile == True:  \n",
    "            epoch_training_acc = get_accuracy(net,train_set)\n",
    "            print('{} -> Acc: {:.4f}'.format(\"training\",epoch_training_acc))\n",
    "            epoch_testing_acc = get_accuracy(net,test_set)\n",
    "            print('{} -> Acc: {:.4f}'.format(\"testing\", epoch_testing_acc))\n",
    "     \n",
    "    return net, history\n",
    "\n",
    "def cross_validation_score_299(data,labels,epochs,cv=5):\n",
    "    chunk_size = int(len(set_data_cv)/cv)\n",
    "    #divide the sets by cv\n",
    "    data_sets = list(chunks(set_data_cv,chunk_size))\n",
    "    label_sets = list(chunks(set_labels_cv,chunk_size))\n",
    "    \n",
    "    OUTPUT_CONV = 27\n",
    "    \n",
    "    nets = []\n",
    "    histories = []\n",
    "    accuracies = []\n",
    "    confmats = []\n",
    "\n",
    "    for i in range(cv):\n",
    "        print(\"------------------------------- \",i,\"/\",cv)\n",
    "\n",
    "        \n",
    "        #foreach cv_sets create training and testing\n",
    "        training_data, prediction_data  = get_separated_sets(data_sets,i)\n",
    "        training_labels, prediction_labels = get_separated_sets(label_sets,i)\n",
    "        print(\"training :\",get_label_quantity(training_labels))\n",
    "        print(\"prediction :\",get_label_quantity(prediction_labels))\n",
    "        \n",
    "        train_dataset = data_loader(training_data,training_labels)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "        test_dataset = data_loader(prediction_data,prediction_labels)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "        \n",
    "        #and train\n",
    "        #reset all model\n",
    "        net = Model()\n",
    "        if GPU == True:\n",
    "            net.cuda()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        #optimizer = torch.optim.Adam(net.parameters())\n",
    "        optimizer =torch.optim.Adam(net.parameters(), 0.1, (0.9, 0.999), 0.1, 5e-05)\n",
    "        #optimizer = torch.optim.Adadelta(net.parameters(), 1.0, 0.9, 1e-06, 5e-05)\n",
    "        c_net,c_hist = trainClassifier(net,train_loader,test_loader,criterion,optimizer,epochs)\n",
    "\n",
    "        nets.append(c_net)\n",
    "        histories.append(c_hist)\n",
    "        \n",
    "        #and get accuracy\n",
    "        c_acc = get_accuracy(c_net,test_loader)\n",
    "        c_confmat = get_stats(c_net,test_loader)\n",
    "        \n",
    "        print(\"Accuracy: %0.2f\" % (c_acc))\n",
    "        \n",
    "        accuracies.append(c_acc)\n",
    "        confmats.append(c_confmat)\n",
    "        \n",
    "    return nets, histories, accuracies, confmats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (299x299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 2/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 3/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 4/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 5/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 6/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 7/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 8/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 9/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 10/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 11/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 12/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 13/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 14/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 15/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 16/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 17/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 18/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 19/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 20/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 21/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 22/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 23/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 24/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 25/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 26/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 27/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 28/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 29/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 30/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 31/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 32/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 33/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 34/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 35/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 36/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 37/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 38/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 39/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 40/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 41/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 42/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 43/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 44/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 45/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 46/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 47/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 48/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 49/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 50/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 51/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 52/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 53/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 54/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 55/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 56/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 57/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 58/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 59/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 60/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 61/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 62/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 63/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 64/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 65/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 66/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 67/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 68/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 69/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 70/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 71/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 72/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 73/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 74/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 75/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 76/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 77/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 78/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 79/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 80/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 81/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 82/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 83/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 84/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 85/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 86/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 87/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 88/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 89/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 90/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 91/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 92/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 93/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 94/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 95/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 96/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 97/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 98/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 99/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n",
      "Epoch 100/100\n",
      "----------\n",
      "training -> Acc: 0.1406\n",
      "testing -> Acc: 0.1406\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "net = Model()\n",
    "if GPU == True:\n",
    "    net.cuda()\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "#optimizer = torch.optim.Adam(net.parameters(), 1.0, (0.9, 0.999), 1.0, 5e-05)\n",
    "#optimizer = torch.optim.Adagrad(net.parameters(), 1.0, 0, 0.1,0)\n",
    "#optimizer = torch.optim.ASGD(net.parameters(), 0.1, 0.0001, 0.75, 1000000.0, 0)\n",
    "#optimizer = torch.optim.Adadelta(net.parameters(), 1.0, 0.9, 1e-06, 5e-05)\n",
    "#optimizer = torch.optim.SGD(net.parameters(),lr=1e-3, momentum=0.9, dampening=0)\n",
    "\n",
    "classifier, loss_history = trainClassifier(net,train_loader,test_loader,criterion,optimizer,N_EPOCHS,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result display (299x299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       t/p      anger contempt  disgust     fear    happy  sadness surprise \n",
      "       anger       18        0        0        0        0        0        0 \n",
      "    contempt        7        0        0        0        0        0        0 \n",
      "     disgust       23        0        0        0        0        0        0 \n",
      "        fear       10        0        0        0        0        0        0 \n",
      "       happy       27        0        0        0        0        0        0 \n",
      "     sadness       11        0        0        0        0        0        0 \n",
      "    surprise       32        0        0        0        0        0        0 \n",
      "-----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      1.00      0.25        18\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00        23\n",
      "           3       0.00      0.00      0.00        10\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.00      0.00      0.00        32\n",
      "\n",
      "   micro avg       0.14      0.14      0.14       128\n",
      "   macro avg       0.02      0.14      0.04       128\n",
      "weighted avg       0.02      0.14      0.03       128\n",
      "\n",
      "Accuracy (299x299) : 0.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_SIZE = 299\n",
    "acc = get_accuracy(classifier,test_loader)\n",
    "confmat,stats = get_stats(classifier,test_loader)\n",
    "\n",
    "print_cm(confmat,emotions)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(stats)\n",
    "print(\"Accuracy (299x299) : %0.2f\" % (acc))\n",
    "plt.plot(np.array(range(len(loss_history))), loss_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation (299x299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n",
      "[5, 4, 1, 5, 2, 1, 3, 4, 0, 6, 6, 2, 0, 1, 6, 4, 0, 5, 2, 6, 6, 6, 6, 6, 6, 6, 3, 0, 4, 6, 4, 6, 3, 2, 2, 6, 5, 5, 6, 4, 4, 0, 0, 3, 0, 3, 6, 2, 0, 4, 0, 6, 6, 1, 2, 5, 2, 5, 4, 0, 4, 4, 4, 0, 6, 4, 4, 4, 2, 6, 6, 2, 0, 4, 3, 6, 5, 2, 4, 3, 2, 6, 1, 4, 2, 0, 4, 0, 4, 4, 4, 6, 3, 2, 6, 6, 6, 0, 6, 1, 4, 2, 1, 2, 6, 0, 2, 3, 2, 0, 6, 2, 4, 5, 5, 2, 6, 4, 4, 4, 2, 5, 2, 3, 0, 2, 6, 6]\n",
      "training : [27. 10. 35. 15. 41. 16. 48.]\n",
      "prediction : [18.  7. 23. 10. 27. 11. 32.]\n",
      "Sum Training:  192.0\n",
      "Sum Testing:  128.0\n",
      "320\n",
      "(299, 299)\n",
      "---------------------------------------------\n",
      "training : [35. 16. 45. 19. 57. 22. 62.]\n",
      "prediction : [10.  1. 13.  6. 11.  5. 18.]\n",
      "---------------------------------------------\n",
      "training : [35. 14. 51. 21. 55. 18. 62.]\n",
      "prediction : [10.  3.  7.  4. 13.  9. 18.]\n",
      "---------------------------------------------\n",
      "training : [36. 14. 43. 20. 53. 24. 66.]\n",
      "prediction : [ 9.  3. 15.  5. 15.  3. 14.]\n",
      "---------------------------------------------\n",
      "training : [37. 13. 42. 21. 52. 23. 68.]\n",
      "prediction : [ 8.  4. 16.  4. 16.  4. 12.]\n",
      "---------------------------------------------\n",
      "training : [37. 11. 51. 19. 55. 21. 62.]\n",
      "prediction : [ 8.  6.  7.  6. 13.  6. 18.]\n",
      "-------------------------------  0 / 5\n",
      "training : [35. 16. 45. 19. 57. 22. 62.]\n",
      "prediction : [10.  1. 13.  6. 11.  5. 18.]\n",
      "Accuracy: 0.16\n",
      "-------------------------------  1 / 5\n",
      "training : [35. 14. 51. 21. 55. 18. 62.]\n",
      "prediction : [10.  3.  7.  4. 13.  9. 18.]\n",
      "Accuracy: 0.16\n",
      "-------------------------------  2 / 5\n",
      "training : [36. 14. 43. 20. 53. 24. 66.]\n",
      "prediction : [ 9.  3. 15.  5. 15.  3. 14.]\n",
      "Accuracy: 0.14\n",
      "-------------------------------  3 / 5\n",
      "training : [37. 13. 42. 21. 52. 23. 68.]\n",
      "prediction : [ 8.  4. 16.  4. 16.  4. 12.]\n",
      "Accuracy: 0.12\n",
      "-------------------------------  4 / 5\n",
      "training : [37. 11. 51. 19. 55. 21. 62.]\n",
      "prediction : [ 8.  6.  7.  6. 13.  6. 18.]\n",
      "Accuracy: 0.12\n",
      "Accuracy: 0.14 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "#Reloead data\n",
    "IMG_SIZE = 299\n",
    "GPU = True\n",
    "DATA_PATH = \"C:/Users/Cerberus/Documents/ML/Project/dataset299\"\n",
    "\n",
    "training_data, training_labels, prediction_data, prediction_labels = make_sets()\n",
    "\n",
    "train_dataset = data_loader(training_data,training_labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = data_loader(prediction_data,prediction_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(training_data[0].shape)\n",
    "print(prediction_labels)\n",
    "print(\"training :\",get_label_quantity(training_labels))\n",
    "print(\"prediction :\",get_label_quantity(prediction_labels))\n",
    "print(\"Sum Training: \", np.sum(get_label_quantity(training_labels)))\n",
    "print(\"Sum Testing: \", np.sum(get_label_quantity(prediction_labels)))\n",
    "\n",
    "set_data_cv, set_labels_cv = make_one_set()\n",
    "print(len(set_labels_cv))\n",
    "\n",
    "cv = 5\n",
    "chunk_size = int(len(set_data_cv)/cv)\n",
    "#divide the sets by cv\n",
    "data_sets = list(chunks(set_data_cv,chunk_size))\n",
    "label_sets = list(chunks(set_labels_cv,chunk_size))\n",
    "\n",
    "print(training_data[0].shape)\n",
    "for i in range(cv):\n",
    "    #foreach cv_sets create training and testing\n",
    "    training_data, prediction_data  = get_separated_sets(data_sets,i)\n",
    "    training_labels, prediction_labels = get_separated_sets(label_sets,i)\n",
    "    #print(\"---------------------------------------------\")\n",
    "    #print(\"training :\",get_label_quantity(training_labels))\n",
    "    #print(\"prediction :\",get_label_quantity(prediction_labels))\n",
    "    \n",
    "N_EPOCHS = 50\n",
    "nets,histories, accuracies, confmats = cross_validation_score_299(set_data_cv,set_labels_cv,N_EPOCHS)\n",
    "\n",
    "acc_mean = np.mean(accuracies, axis=0)\n",
    "acc_dev = np.std(accuracies, axis=0)\n",
    "print(\"=========================================\")\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (acc_mean, acc_dev * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (48x48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CONV = 2\n",
    "\n",
    "#img -> 48*48\n",
    "class Model_48(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model_48, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 15)\n",
    "        self.avgpool2d = nn.AvgPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(10,10,12)\n",
    "        self.maxpool2d = nn.MaxPool2d(5,5,2)\n",
    "        self.fc1 = nn.Linear(10*OUTPUT_CONV*OUTPUT_CONV, 20)\n",
    "        self.fc2 = nn.Linear(20, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x \", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(\"conv1 \", x.shape)\n",
    "        x = self.avgpool2d(x)\n",
    "        #print(\"avgpool2d \", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(\"conv2 \", x.shape)\n",
    "        x = self.maxpool2d(x)\n",
    "        #print(\"maxpool2d \", x.shape)\n",
    "        x = x.view(-1, 10*OUTPUT_CONV*OUTPUT_CONV)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        result = F.relu(self.fc2(x))\n",
    "        #result = F.softmax(x, dim=1)\n",
    "        return result\n",
    "    \n",
    "def cross_validation_score_48(data,labels,epochs,cv=5):\n",
    "    chunk_size = int(len(set_data_cv)/cv)\n",
    "    #divide the sets by cv\n",
    "    data_sets = list(chunks(set_data_cv,chunk_size))\n",
    "    label_sets = list(chunks(set_labels_cv,chunk_size))\n",
    "    \n",
    "    nets = []\n",
    "    histories = []\n",
    "    accuracies = []\n",
    "    confmats = []\n",
    "\n",
    "    for i in range(cv):\n",
    "        print(\"------------------------------- \",i,\"/\",cv)\n",
    "\n",
    "        \n",
    "        #foreach cv_sets create training and testing\n",
    "        training_data, prediction_data  = get_separated_sets(data_sets,i)\n",
    "        training_labels, prediction_labels = get_separated_sets(label_sets,i)\n",
    "        print(\"training :\",get_label_quantity(training_labels))\n",
    "        print(\"prediction :\",get_label_quantity(prediction_labels))\n",
    "        \n",
    "        train_dataset = data_loader(training_data,training_labels)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "        test_dataset = data_loader(prediction_data,prediction_labels)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "        \n",
    "        #and train\n",
    "        #reset all model\n",
    "        net = Model_48()\n",
    "        if GPU == True:\n",
    "            net.cuda()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(net.parameters())\n",
    "        #optimizer =torch.optim.Adam(net.parameters(), 0.1, (0.9, 0.999), 0.1, 5e-05)\n",
    "        #optimizer = torch.optim.Adadelta(net.parameters(), 1.0, 0.9, 1e-06, 5e-05)\n",
    "        c_net,c_hist = trainClassifier(net,train_loader,test_loader,criterion,optimizer,epochs)\n",
    "\n",
    "        nets.append(c_net)\n",
    "        histories.append(c_hist)\n",
    "        \n",
    "        #and get accuracy\n",
    "        c_acc = get_accuracy(c_net,test_loader)\n",
    "        c_confmat = get_stats(c_net,test_loader)\n",
    "        \n",
    "        print(\"Accuracy: %0.2f\" % (c_acc))\n",
    "        \n",
    "        accuracies.append(c_acc)\n",
    "        confmats.append(c_confmat)\n",
    "        \n",
    "    return nets, histories, accuracies, confmats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading (48x48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path:  C:/Users/Cerberus/Documents/ML/Project/dataset48\n",
      "Image size:  48\n",
      "GPU enabled:  True\n",
      "[1, 3, 2, 4, 0, 4, 5, 4, 4, 6, 0, 0, 0, 5, 4, 6, 3, 1, 3, 2, 5, 4, 2, 0, 4, 6, 3, 2, 4, 6, 2, 2, 6, 6, 6, 4, 2, 6, 0, 6, 4, 4, 6, 6, 4, 0, 4, 0, 6, 0, 2, 5, 3, 2, 0, 6, 6, 6, 1, 4, 2, 0, 6, 4, 3, 2, 0, 1, 4, 3, 0, 0, 5, 4, 2, 0, 6, 5, 4, 3, 2, 6, 6, 4, 2, 6, 4, 2, 6, 5, 6, 6, 6, 4, 4, 4, 6, 6, 2, 5, 2, 1, 2, 2, 6, 6, 2, 4, 2, 5, 6, 1, 0, 1, 6, 5, 5, 2, 6, 3, 6, 6, 3, 0, 2, 4, 4, 4, 0]\n",
      "training : [27. 10. 35. 15. 41. 16. 49.]\n",
      "prediction : [18.  7. 23. 10. 27. 11. 33.]\n",
      "Sum Training:  193.0\n",
      "Sum Testing:  129.0\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 48\n",
    "GPU = True\n",
    "DATA_PATH = \"C:/Users/Cerberus/Documents/ML/Project/dataset48\"\n",
    "\n",
    "print(\"Data path: \",DATA_PATH)\n",
    "print(\"Image size: \",IMG_SIZE)\n",
    "print(\"GPU enabled: \",GPU)\n",
    "\n",
    "training_data, training_labels, prediction_data, prediction_labels = make_sets()\n",
    "\n",
    "train_dataset = data_loader(training_data,training_labels)\n",
    "train_loader48 = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = data_loader(prediction_data,prediction_labels)\n",
    "test_loader48 = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "print(prediction_labels)\n",
    "print(\"training :\",get_label_quantity(training_labels))\n",
    "print(\"prediction :\",get_label_quantity(prediction_labels))\n",
    "print(\"Sum Training: \", np.sum(get_label_quantity(training_labels)))\n",
    "print(\"Sum Testing: \", np.sum(get_label_quantity(prediction_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (48x48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "training -> Acc: 0.2591\n",
      "testing -> Acc: 0.2558\n",
      "Epoch 2/100\n",
      "----------\n",
      "training -> Acc: 0.5492\n",
      "testing -> Acc: 0.5194\n",
      "Epoch 3/100\n",
      "----------\n",
      "training -> Acc: 0.5959\n",
      "testing -> Acc: 0.5581\n",
      "Epoch 4/100\n",
      "----------\n",
      "training -> Acc: 0.7150\n",
      "testing -> Acc: 0.6899\n",
      "Epoch 5/100\n",
      "----------\n",
      "training -> Acc: 0.7254\n",
      "testing -> Acc: 0.6279\n",
      "Epoch 6/100\n",
      "----------\n",
      "training -> Acc: 0.7098\n",
      "testing -> Acc: 0.6667\n",
      "Epoch 7/100\n",
      "----------\n",
      "training -> Acc: 0.6943\n",
      "testing -> Acc: 0.6744\n",
      "Epoch 8/100\n",
      "----------\n",
      "training -> Acc: 0.7565\n",
      "testing -> Acc: 0.6589\n",
      "Epoch 9/100\n",
      "----------\n",
      "training -> Acc: 0.6943\n",
      "testing -> Acc: 0.5814\n",
      "Epoch 10/100\n",
      "----------\n",
      "training -> Acc: 0.7720\n",
      "testing -> Acc: 0.6899\n",
      "Epoch 11/100\n",
      "----------\n",
      "training -> Acc: 0.7772\n",
      "testing -> Acc: 0.6899\n",
      "Epoch 12/100\n",
      "----------\n",
      "training -> Acc: 0.7824\n",
      "testing -> Acc: 0.7054\n",
      "Epoch 13/100\n",
      "----------\n",
      "training -> Acc: 0.6632\n",
      "testing -> Acc: 0.5736\n",
      "Epoch 14/100\n",
      "----------\n",
      "training -> Acc: 0.7824\n",
      "testing -> Acc: 0.7054\n",
      "Epoch 15/100\n",
      "----------\n",
      "training -> Acc: 0.7772\n",
      "testing -> Acc: 0.7132\n",
      "Epoch 16/100\n",
      "----------\n",
      "training -> Acc: 0.6736\n",
      "testing -> Acc: 0.6124\n",
      "Epoch 17/100\n",
      "----------\n",
      "training -> Acc: 0.7824\n",
      "testing -> Acc: 0.7054\n",
      "Epoch 18/100\n",
      "----------\n",
      "training -> Acc: 0.7824\n",
      "testing -> Acc: 0.6977\n",
      "Epoch 19/100\n",
      "----------\n",
      "training -> Acc: 0.7824\n",
      "testing -> Acc: 0.6977\n",
      "Epoch 20/100\n",
      "----------\n",
      "training -> Acc: 0.7824\n",
      "testing -> Acc: 0.6977\n",
      "Epoch 21/100\n",
      "----------\n",
      "training -> Acc: 0.7876\n",
      "testing -> Acc: 0.6899\n",
      "Epoch 22/100\n",
      "----------\n",
      "training -> Acc: 0.6684\n",
      "testing -> Acc: 0.5659\n",
      "Epoch 23/100\n",
      "----------\n",
      "training -> Acc: 0.7979\n",
      "testing -> Acc: 0.6899\n",
      "Epoch 24/100\n",
      "----------\n",
      "training -> Acc: 0.8290\n",
      "testing -> Acc: 0.7132\n",
      "Epoch 25/100\n",
      "----------\n",
      "training -> Acc: 0.8083\n",
      "testing -> Acc: 0.6899\n",
      "Epoch 26/100\n",
      "----------\n",
      "training -> Acc: 0.8238\n",
      "testing -> Acc: 0.6899\n",
      "Epoch 27/100\n",
      "----------\n",
      "training -> Acc: 0.8135\n",
      "testing -> Acc: 0.6822\n",
      "Epoch 28/100\n",
      "----------\n",
      "training -> Acc: 0.8238\n",
      "testing -> Acc: 0.7054\n",
      "Epoch 29/100\n",
      "----------\n",
      "training -> Acc: 0.8497\n",
      "testing -> Acc: 0.7287\n",
      "Epoch 30/100\n",
      "----------\n",
      "training -> Acc: 0.7876\n",
      "testing -> Acc: 0.6667\n",
      "Epoch 31/100\n",
      "----------\n",
      "training -> Acc: 0.8290\n",
      "testing -> Acc: 0.6822\n",
      "Epoch 32/100\n",
      "----------\n",
      "training -> Acc: 0.8187\n",
      "testing -> Acc: 0.6744\n",
      "Epoch 33/100\n",
      "----------\n",
      "training -> Acc: 0.8342\n",
      "testing -> Acc: 0.7209\n",
      "Epoch 34/100\n",
      "----------\n",
      "training -> Acc: 0.8497\n",
      "testing -> Acc: 0.7054\n",
      "Epoch 35/100\n",
      "----------\n",
      "training -> Acc: 0.8497\n",
      "testing -> Acc: 0.7287\n",
      "Epoch 36/100\n",
      "----------\n",
      "training -> Acc: 0.8497\n",
      "testing -> Acc: 0.7364\n",
      "Epoch 37/100\n",
      "----------\n",
      "training -> Acc: 0.8549\n",
      "testing -> Acc: 0.7209\n",
      "Epoch 38/100\n",
      "----------\n",
      "training -> Acc: 0.8549\n",
      "testing -> Acc: 0.7287\n",
      "Epoch 39/100\n",
      "----------\n",
      "training -> Acc: 0.8601\n",
      "testing -> Acc: 0.7209\n",
      "Epoch 40/100\n",
      "----------\n",
      "training -> Acc: 0.8601\n",
      "testing -> Acc: 0.7287\n",
      "Epoch 41/100\n",
      "----------\n",
      "training -> Acc: 0.8601\n",
      "testing -> Acc: 0.7364\n",
      "Epoch 42/100\n",
      "----------\n",
      "training -> Acc: 0.8601\n",
      "testing -> Acc: 0.7132\n",
      "Epoch 43/100\n",
      "----------\n",
      "training -> Acc: 0.8601\n",
      "testing -> Acc: 0.7287\n",
      "Epoch 44/100\n",
      "----------\n",
      "training -> Acc: 0.8601\n",
      "testing -> Acc: 0.7442\n",
      "Epoch 45/100\n",
      "----------\n",
      "training -> Acc: 0.8601\n",
      "testing -> Acc: 0.7442\n",
      "Epoch 46/100\n",
      "----------\n",
      "training -> Acc: 0.8601\n",
      "testing -> Acc: 0.7287\n",
      "Epoch 47/100\n",
      "----------\n",
      "training -> Acc: 0.5648\n",
      "testing -> Acc: 0.5116\n",
      "Epoch 48/100\n",
      "----------\n",
      "training -> Acc: 0.5855\n",
      "testing -> Acc: 0.5271\n",
      "Epoch 49/100\n",
      "----------\n",
      "training -> Acc: 0.8290\n",
      "testing -> Acc: 0.6899\n",
      "Epoch 50/100\n",
      "----------\n",
      "training -> Acc: 0.8394\n",
      "testing -> Acc: 0.6977\n",
      "Epoch 51/100\n",
      "----------\n",
      "***********************************\n",
      "NO TRAINING:  3  times the same loss\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "net48 = Model_48()\n",
    "if GPU == True:\n",
    "    net48.cuda()\n",
    "    \n",
    "criterion48 = torch.nn.CrossEntropyLoss()\n",
    "optimizer48 = torch.optim.Adam(net48.parameters())\n",
    "#optimizer48 = torch.optim.Adam(net48.parameters(), 1.0, (0.9, 0.999), 1.0, 5e-05)\n",
    "#optimizer48 = torch.optim.Adagrad(net48.parameters(), 1.0, 0, 0.1,0)\n",
    "#optimizer48 = torch.optim.ASGD(net48.parameters(), 0.1, 0.0001, 0.75, 1000000.0, 0)\n",
    "#optimizer48 = torch.optim.Adadelta(net48.parameters(), 1.0, 0.9, 1e-06, 5e-05)\n",
    "#optimizer48 = torch.optim.SGD(net48.parameters(),lr=1e-3, momentum=0.9, dampening=0)\n",
    "\n",
    "classifier48, loss_history48 = trainClassifier(net48,train_loader48,test_loader48,criterion48,optimizer48,N_EPOCHS,True,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result display(48x48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       t/p      anger contempt  disgust     fear    happy  sadness surprise \n",
      "       anger       18        0        0        0        0        0        0 \n",
      "    contempt        6        0        0        1        0        0        0 \n",
      "     disgust        2        0       21        0        0        0        0 \n",
      "        fear        3        0        0        7        0        0        0 \n",
      "       happy        2        0        0        0       25        0        0 \n",
      "     sadness       10        0        0        0        0        0        1 \n",
      "    surprise        2        0        0        0        0        0       31 \n",
      "-----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59        18\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       1.00      0.91      0.95        23\n",
      "           3       0.88      0.70      0.78        10\n",
      "           4       1.00      0.93      0.96        27\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.97      0.94      0.95        33\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       129\n",
      "   macro avg       0.61      0.64      0.61       129\n",
      "weighted avg       0.76      0.79      0.76       129\n",
      "\n",
      "Accuracy (48x48) : 0.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_SIZE = 48\n",
    "OUTPUT_CONV = 2\n",
    "\n",
    "\n",
    "acc48 = get_accuracy(classifier48,test_loader48)\n",
    "confmat48,stats48 = get_stats(classifier48,test_loader48)\n",
    "\n",
    "print_cm(confmat48,emotions)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(stats48)\n",
    "print(\"Accuracy (48x48) : %0.2f\" % (acc48))\n",
    "plt.plot(np.array(range(len(loss_history48))), loss_history48)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation (48x48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "(48, 48)\n",
      "-------------------------------  0 / 5\n",
      "training : [34. 10. 48. 21. 51. 25. 69.]\n",
      "prediction : [11.  7. 10.  4. 17.  2. 13.]\n",
      "Accuracy: 0.73\n",
      "-------------------------------  1 / 5\n",
      "training : [39. 14. 48. 20. 57. 22. 58.]\n",
      "prediction : [ 6.  3. 10.  5. 11.  5. 24.]\n",
      "Accuracy: 0.73\n",
      "-------------------------------  2 / 5\n",
      "training : [34. 16. 45. 20. 51. 22. 70.]\n",
      "prediction : [11.  1. 13.  5. 17.  5. 12.]\n",
      "Accuracy: 0.17\n",
      "-------------------------------  3 / 5\n",
      "training : [37. 13. 42. 23. 56. 20. 67.]\n",
      "prediction : [ 8.  4. 16.  2. 12.  7. 15.]\n",
      "Accuracy: 0.72\n",
      "-------------------------------  4 / 5\n",
      "training : [36. 15. 49. 16. 57. 19. 64.]\n",
      "prediction : [ 9.  2.  9.  9. 11.  8. 18.]\n",
      "Accuracy: 0.14\n",
      "=========================================\n",
      "Accuracy: 0.50 (+/- 0.56)\n"
     ]
    }
   ],
   "source": [
    "set_data_cv, set_labels_cv = make_one_set()\n",
    "print(len(set_labels_cv))\n",
    "\n",
    "cv = 5\n",
    "chunk_size = int(len(set_data_cv)/cv)\n",
    "#divide the sets by cv\n",
    "data_sets = list(chunks(set_data_cv,chunk_size))\n",
    "label_sets = list(chunks(set_labels_cv,chunk_size))\n",
    "\n",
    "print(training_data[0].shape)\n",
    "for i in range(cv):\n",
    "    #foreach cv_sets create training and testing\n",
    "    training_data, prediction_data  = get_separated_sets(data_sets,i)\n",
    "    training_labels, prediction_labels = get_separated_sets(label_sets,i)\n",
    "    #print(\"---------------------------------------------\")\n",
    "    #print(\"training :\",get_label_quantity(training_labels))\n",
    "    #print(\"prediction :\",get_label_quantity(prediction_labels))\n",
    "    \n",
    "N_EPOCHS = 50\n",
    "nets,histories, accuracies, confmats = cross_validation_score_48(set_data_cv,set_labels_cv,N_EPOCHS)\n",
    "\n",
    "acc_mean = np.mean(accuracies, axis=0)\n",
    "acc_dev = np.std(accuracies, axis=0)\n",
    "print(\"=========================================\")\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (acc_mean, acc_dev * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
